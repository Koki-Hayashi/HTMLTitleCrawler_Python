コメント

・動作環境
->環境構築する時間が取れなかったので、Nitorous.ioを使って開発しました。(https://www.nitrous.io/)
Nitorous.io上以外での動作確認ができていないので、万が一動かなかった場合はご一報ください。
一応、下記OSでの動作確認済みです。Mac、Windows、その他OSでの環境は動作確認ができていません。
cat /etc/lsb-release
DISTRIB_ID=Ubuntu
DISTRIB_RELEASE=14.04
DISTRIB_CODENAME=trusty
DISTRIB_DESCRIPTION="Ubuntu 14.04.2 LTS"

・pythonのバージョン
python --version
Python 2.7.6

・文字列のマッチング
-> 正規表現で行っています。

・バリデーションチェック
->それぞれのファイルに関して、下記のようなチェックを行っています。
- word_list.txt
  - ファイル名が空文字もしくはNoneでないこと
  - ファイルが存在すること
  - 各行が空行でないこと
  - 各単語がスペース文字を含まないこと(複数単語でないこと)
- url_list.txt
  - ファイル名が空文字もしくはNoneでないこと
  - ファイルが存在すること
  - 各行が空行でないこと
  - 各urlがスペース文字を含まないこと-
- output.tsv
  - ファイル名が空文字もしくはNoneでないこと
  - 指定ディレクトリが存在すること

なお、word_list、url_listでは単語/urlが重複して指定されていた場合でも、そのままにしています。
その場合、結果も重複して出力されます。


--------------　以下オリジナルの問題文　--------------


■ 概要

単語のリストとURLのリストを読み込んでWebページをクローリングし、各Webページのタイトル中に含まれる
各単語数をTSV形式で出力していただくプログラムを書いていただきます。出力する単語数に関しては実行時に指定した単語リスト中のものに限ります。
言語に関してはPython, もしくはGoでお願いいたします。バージョンに関しては特に指定は行いません。

■ 仕様

1. プログラム実行時の入出力

1.1. 実行形式

$ python crawler.py <word_list.txt> <url_list.txt> <output.tsv>

上記形式のように第一引数に単語のリスト、第二引数にURLのリストを読み込むようにする。

1.2. 単語リストのフォーマット

$ cat word_list.txt
Momentum
株式会社
広告
アドテク

上記形式のように1行1単語で書かれているものとします。
単語は1つ以上入力されるものとします。文字コードはUTF8前提でよいです。

1.3. URLリストのフォーマット

$ cat url_list.txt
http://www.m0mentum.co.jp/
http://www.m0mentum.co.jp/service/blackswan.html
http://www.m0mentum.co.jp/news.html
http://example.com/notfound.html

上記形式のように1行1URLで書かれているものとします。
URLは1つ以上入力されるものとします。文字コードはUTF8前提でよいです。

1.4. URLについて

HTML文書以外を指すURLが入力されることもありますが、タイトル抽出の処理対象外としていただいて構いません。(1.5.にもありますように結果には含める必要はあります。)またURLが指す文書の文字エンコーディングに関してはUTF8前提でよいです。

1.5. 出力形式について

1.1の<output.tsv> に指定したファイルパスに対してTSV形式で結果を出力していただきます。
1.2., 1.3.のような入力ファイルである場合、以下のような出力形式でお願いします。

# 対象URL "Momentum"の出現数 "株式会社"の出現数 "広告"の出現数 "アドテク"の出現数
http://www.m0mentum.co.jp/\t1\t1\t1\t0
http://www.m0mentum.co.jp/service/blackswan.html\t1\t1\t1\t0
http://www.m0mentum.co.jp/news.html\t1\t1\t1\t0
http://example.com/notfound.html\t0\t0\t0\t0

URLの並び順については、入力URLのリストの行番号の昇順でお願いいたします。
単語の出現数の並び順については、単語リストの行番号の昇順でお願いいたします。

http://example.com/notfound.html のような存在しないURLであった場合は、出現数を0にして行に含んでください。

1.6. バリデーションチェックについて

標準標準エラー出力にで構いませんので、このような要求仕様に対して必要と思われる出力を行ってください。詳細についてはお任せいたします。

2. Webページのタイトル文字列解析

2.1. タイトルの抽出方法

URLが指すHTML文書中の<title>タグ中のテキストをタイトルとしてください。

2.2. 単語数のカウントについて

1.2.で与えられた各単語の出現頻度をHTMLページごとに出していただきます。
タイトル文字列を部分一致もしくは、MeCabなどの形態素解析器を用いて切り出し1単語として各単語とマッチさせてください。文字列のマッチングの仕様に関してはお任せいたします。

3. クローリング部分

3.1. URLの読み込み
シングルスレッドでHTTPでWebページの読み込みをするとその間処理をブロックしてしまうので、
Pythonならthreadingモジュール、Goならgoroutineを利用して非同期な処理とし効率化をはかっていただきます。

4. 利用可能ライブラリについて

形態素解析器を使う場合のみ、MeCabなどのライブラリの利用を許可いたします。

5. 想定時間

3,4時間ほどで実装完了するレベルを想定しております。

6. 提出方法

Githubで弊社のプライベートリポジトリを作成してそちらにPushしていただきます。
Githubの利用には個人のGithubアカウントが必要となります。




